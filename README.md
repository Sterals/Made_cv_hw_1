# Made_cv_hw_1
Отчетность по первому дз (соревнованию) по cv в академии MADE

## Комментарии по коду.
Код исполнялся на колабе, поэтому все ссылки на сохранение и загрузку данных ведут на примонтированный Google диск. Ячейки в которых выполнялось разархивирование данных закомментированы, но они приводили к тому что в корне формируется папка data, в которую дополнительно копируется test_points.csv. Версия основана на бейзлайне. 

## Основные исследования.
Действовал в соответствии с указаниями в соревновании.
"
От участников ожидается не просто GridSearch по архитектурам, но и:

Работа с рутиной обучения (подбор параметров оптимизаторов, режимов обучения, хитрых лоссов, …)
"
### GridSearch по архитектурам.
В подборе архитектуры руководствовался скором на ImageNet на сайте:
https://pytorch.org/docs/stable/torchvision/models.html

Попробовал ResNet-18, ResNet-34, VGG-16, ResNet-50, ResNet-101, ResNet-152, ResNeXt-50-32x4d, Inception v3
Inception не влез даже со батчем в 128.<br>
VGG дал скор на валидационной части сильно ниже даже чем резнет18 (хотя мб я не доучил. Было 10 эпох, лр не менял.)<br>
Лучше всего (и примерно одинаково) на 10 эпохах себя показали (ResNet-50 (256), ResNet-101 (256), ResNeXt-50-32x4d (256)).<br>Лучший скор на валидационной части дал ResNet-101 (256), но на паблике почти столько же давал ResNeXt-50-32x4d (256). Второй учился быстрее в среднем на 5 минут на эпоху, в следствии чего в финальную версию пошел он.

### Подбор параметров оптимизаторов.
Попробовал Adam, AdamW, ReduceLROnPlateau.<br>
Пробовал учить 5-7 эпох с одним (до сходимости оценки на валидационном сете) и менять оптимизатор/ параметры.<br>
ReduceLROnPlateau - не дал заметных улучшений. Adam и AdamW тоже сильно не отличались.<br>
Пробовал после 6 эпох Adam учить AdamW, но сходимость была примерно такой же.<br>
Пробовал учить на Adam(10e-3) 6 эпох, а затем каждые две эпохи уменьшать LR на порядок. Это решение давало лучшую сходимость на валидационном сете. Но в целом хватало 1-2 уменьшений. <br>
Пробовал после сходимости увеличить LR, а затем, через пару эпох опять уменьшить. Значимых результатов это не принесло.

### Подбор режимов обучения.
Прочитал про 20-30 эпох от человека с 5 местом и понял, что я не такой терпеливый. У меня максимум было 20 эпох. Так как сходилось все уже к 10, а с уменьшением LR к 15. Результирующий вариант, который давал хороший результат следующий: 8 эпох с LR (10e-3), 4 эпохи c  LR (10e-4). Оптимизатор Adam. Архитектура ResNeXt-50-32x4d или ResNet-101.

### Подбор хитрых лоссов.
Очень с сомнением относился к данному пункту, так как MSE в чистом виде представлено только torch.nn.MSELoss, а метрика соревнования MSE. Но на последней неделе, когда я с +-20 места улетел на 50 и никак не мог пробить 10 MSE на лб, а люди заходили в 8-9 с 2-5 сабмитов, я понял, что что-то я не учитываю. Еще раз прочитал ваши советы по соревнованиям и задумался про хитрые лоссы.<br>
Нашел статью на медиуме: https://medium.com/udacity-pytorch-challengers/a-brief-overview-of-loss-functions-in-pytorch-c0ddb78068f7 <br>
Попробовал SmoothL1Loss. Без понижения LR сошлась также на ЛБ, как MSE на 10 эпохах. Но с понижением после 8 эпох до 10e-4, вышла немного лучше, чем MSE в чистом виде (0.5 на паблике и 0.2 на прайват лб). Дальнейшую сходимость не доисследовал. Возможно, можно было бы добиться еще лучшей оценки. Но не уверен, что это хороший подход, так как мне не интуитивно ясно, что SmoothL1Loss и MSE имеют минимум в одной и той же точке.

### Что еще хотелось попробовать, но не хватило времени.
Не сравнил финальную версию на ResNeXt-50-32x4d с ResNet-101. Второй мог дать метрику лучше.<br>
В выборке присутствовали картинки с плохой разметкой. Не придумал что с ними делать.<br>
С запуском соревнования надеялся пощупать albumentation, так как ну очень уж его хвалят в сообществе. Но в результате так и не добрался даже до обычных аугментаций. Надеюсь, во втором соревновании дойдут руки.<br>
Ансамблирование (блендинг) принципиально не использовал, так как теряется интерпретируемость. Хотелось понимать, какой параметр дает прирост.<br>

## Скриншот с сабмитами
![Alt text](./img/1.png?raw=true "Title")
